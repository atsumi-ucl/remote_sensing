---
title: "Week 1"
author: "Atsumi Hirose"
editor: visual
--


# Summary

Among the many points addressed in the lecture were: 1. Earth Observation data uses electromagnetic radiation reflected or emitted from the object or area of interest that travels at the speed of light (because electromagnetic radiation is light itself!?!?). and 2. Some objects, or rather, electromagnetic radiation in a certain spectrum which cannot be viewed by human eyes can be detected by satellite sensors to allow human eyes to see them. Because colours are nothing but light, and light is nothing but electromagnetic radiation and electromagnetic radiation consists of different waves which is part of the electromagnetic spectrum ?!?! And human eyes can only see only a small range within the electromagnetic radiation spectrum! (this blows my mind as I write. Am I supposed to have known this as someone who finished primary education a number of years ago?)

![](light%20electromagnetic%20radiation.png)

Take leaves or vegetation as an example. They can be viewed in the visible spectrum but also in the near-infrared light.

Firstly, why leaves green? Wavelengths in the green region of the electromagnetic spectrum are reflected by pigments in the leaf' (NASA Science). That's why we see green leaves. But also 'a plant with more chlorophyll (pigment) will reflect more near-infrared energy than an unhealthy plant' (NASA Science). So this is why with satellite imagery, we can use both the visible and invisible near-infrared spectrum to study vegetation.

SCATTERING: Why is the sky black on the moon? (no atmosphere) Why is the sky blue? (short waves scattered) Why is the sky red when the sun goes down?

Why is the ocean blue? - water absorbs the red yellow and green waves but reflects /scatters blue.

Finally, there are two types of sensors to record electromagnetic radiation.

1\. Passive sensors record EMR reflected or emitted from the terrain.

2\. Active sensors such as LiDAR (on aircrafts), SAR or RADAR emit electromagnetic waves and record the amount of radiant flux (energy per unit of time) that travelled back to the sensors. These are used to develop the DEM, digital elevation model, using the speed of travel to measure the distance between the point on the terrain and the location of the sensor. SAR can see through clouds.

# Application

1.  What drew me to Earth Observation data in the first place is my frustration due the lack of granularity of urban/rural classifications in population-based health surveys. There is usually only two groups of residence: urban or rural. But when I got to know that satellite imagery may be used to classify urban settlements into formal and informal settlements, I got interested in exploring this further. Different characteristics of informal settlements can be used in combination of ML classification tasks. [@kuffer2016]

For this week's practical session, I downloaded data from sentinel 2 of Kampala region (Uganda). With the 10 meter spectoral resolution, it was not possible to see a house, which limits the ability to separete houses in slum communities from those in non-slum communities. 

2.  In the field of global public health, malaria or infectious disease epidemiologists have been the forerunner in using geospatial data including Earth Observation data. For example, this paper by @Brousse2020 uses the urban classification data, based on the Local Climate Zone map which is developed based on satellite imagery, to predict malaria prevalence.

3.  Surface temperature

    'Heat' is such a big topic these days. Many climate & health research investigates the effect of 'heat' on health. How can we get land surface temperature data? I read that Land Surface Temperature is derived from thermal infrared data, which is in the wavelength range of 0.75 -15 Î¼m. This particular wavelength range can be recorded by a multispectoral scanner on Landsat 8, MODIS, ASTER etc etc.

# Reflection

It has taken me some time to absorb this week's concept. What has helped me understand is the fact that there is no such thing as colour, "colours do not exist, what exist is light". Different objects reflect or absorb light in different ways (eg as I explained of green leaves) and satellite sensors and earth observation data take advantage of this feature. The scatterplots of band 4 (red) and band 8 (near infrared) was interesting and makes sense now - something I didn't really understand before, but now I got it - because green vegetation will absorb red but reflect green, satellite sensors would capture a high value of green but a low value of red. 
